{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "pkEiwECpXktX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "OtCOE0koY16M"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training data in a folder and call it cnn_data\n",
        "train_data = datasets.MNIST(root= '/cnn_data', train= True, download= True, transform= transform)"
      ],
      "metadata": {
        "id": "0UEmigIYhzZA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the test data in the same way\n",
        "test_data = datasets.MNIST(root= '/cnn_data', train= False, download= True, transform= transform)"
      ],
      "metadata": {
        "id": "Kx6MM4BijEeH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size= 10, shuffle= True)\n",
        "test_loader = DataLoader(test_data, batch_size= 10, shuffle= True)"
      ],
      "metadata": {
        "id": "fYVmKpDGj3oH"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the architecture step by step"
      ],
      "metadata": {
        "id": "P5PgFh5L8o8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the convolution layer\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "CAPpujrUo99G"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab 1 MNIST image/record\n",
        "for i, (X_train, Y_train) in enumerate(train_data):\n",
        "    break"
      ],
      "metadata": {
        "id": "SWJ_N83FpcU_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd0lVUR8qqWw",
        "outputId": "e2967cf3-3a37-40f9-b8a4-78129d65468a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust the shape of X_train\n",
        "X = X_train.view(1, 1, 28, 28)"
      ],
      "metadata": {
        "id": "W3jbdi20qutk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = F.relu(conv1(X))\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z-BGKujsopV",
        "outputId": "dda5d351-1614-42fc-df47-9249009c2522"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = F.max_pool2d(X, 2, 2)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnR90SVNs8e3",
        "outputId": "06995765-0cc4-466d-97ac-56d2fc65d455"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = F.relu(conv2(X))\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZme060XvMdS",
        "outputId": "b892d2dd-4c33-4e02-b081-72846c6da6e3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = F.max_pool2d(X, 2, 2)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5IrR4frvRww",
        "outputId": "6a216220-1035-4eda-d4ef-0036c14b97c7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a class to define the model architecture"
      ],
      "metadata": {
        "id": "enSvpYHv8fsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "     super().__init__()\n",
        "     self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "     self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "     # fully connected layers\n",
        "     self.fc1 = nn.Linear(5*5*16, 120)\n",
        "     self.fc2 = nn.Linear(120, 84)\n",
        "     self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X)) # this is considered 1 perceptron\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "\n",
        "    X = F.relu(self.conv2(X)) # Changed from self.conv1 to self.conv2\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "\n",
        "\n",
        "    # reshape\n",
        "    X = X.view(-1, 16*5*5)\n",
        "\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = X = self.fc3(X)\n",
        "\n",
        "    return F.log_softmax(X, dim= 1)"
      ],
      "metadata": {
        "id": "y3o4n4EF8m4a"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVkvqDeCTcnz",
        "outputId": "38d64b21-683c-4d36-8dd6-d67152a95e9f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Smaller the Learning Rate, longer its gonna take to train."
      ],
      "metadata": {
        "id": "JGI34hBqPwqQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Create Variables To Tracks Things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# For Loop of Epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "\n",
        "  # Train\n",
        "  for b,(X_train, Y_train) in enumerate(train_loader):\n",
        "    b+=1 # start our batches at 1\n",
        "    y_pred = model(X_train) # get predicted values from the training set. Not flattened 2D\n",
        "    loss = criterion(y_pred, Y_train) # how off are we? Compare the predictions to correct answers in y_train\n",
        "\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # add up the number of correct predictions. Indexed off the first point\n",
        "    batch_corr = (predicted == Y_train).sum() # how many we got correct from this batch. True = 1, False=0, sum those up\n",
        "    trn_corr += batch_corr # keep track as we go along in training.\n",
        "\n",
        "    # Update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # Print out some results\n",
        "    if b%600 == 0:\n",
        "      print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "\n",
        "  # Test\n",
        "  with torch.no_grad(): #No gradient so we don't update our weights and biases with test data\n",
        "    for b,(X_test, Y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data, 1)[1] # Adding up correct predictions\n",
        "      tst_corr += (predicted == Y_test).sum() # T=1 F=0 and sum away\n",
        "\n",
        "\n",
        "  loss = criterion(y_val, Y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "\n",
        "\n",
        "current_time = time.time()\n",
        "total = current_time - start_time\n",
        "print(f'Training Took: {total/60} minutes!')"
      ],
      "metadata": {
        "id": "lWA5hBFKQSZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0c9e98-e42b-4835-dc10-cfb0818ca44d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0  Batch: 600  Loss: 0.1623610556125641\n",
            "Epoch: 0  Batch: 1200  Loss: 0.1502392590045929\n",
            "Epoch: 0  Batch: 1800  Loss: 0.4744560718536377\n",
            "Epoch: 0  Batch: 2400  Loss: 0.14238706231117249\n",
            "Epoch: 0  Batch: 3000  Loss: 0.007758188061416149\n",
            "Epoch: 0  Batch: 3600  Loss: 0.3836284875869751\n",
            "Epoch: 0  Batch: 4200  Loss: 0.0038223876617848873\n",
            "Epoch: 0  Batch: 4800  Loss: 0.0021286322735249996\n",
            "Epoch: 0  Batch: 5400  Loss: 0.0569545142352581\n",
            "Epoch: 0  Batch: 6000  Loss: 0.00038789428072050214\n",
            "Epoch: 1  Batch: 600  Loss: 0.02950388565659523\n",
            "Epoch: 1  Batch: 1200  Loss: 0.01223783753812313\n",
            "Epoch: 1  Batch: 1800  Loss: 0.0017079260433092713\n",
            "Epoch: 1  Batch: 2400  Loss: 0.004794587381184101\n",
            "Epoch: 1  Batch: 3000  Loss: 0.00012589071411639452\n",
            "Epoch: 1  Batch: 3600  Loss: 0.006774441804736853\n",
            "Epoch: 1  Batch: 4200  Loss: 0.00024002441205084324\n",
            "Epoch: 1  Batch: 4800  Loss: 0.011869433335959911\n",
            "Epoch: 1  Batch: 5400  Loss: 0.0003403539885766804\n",
            "Epoch: 1  Batch: 6000  Loss: 0.0003896451380569488\n",
            "Epoch: 2  Batch: 600  Loss: 0.21024510264396667\n",
            "Epoch: 2  Batch: 1200  Loss: 0.11387525498867035\n",
            "Epoch: 2  Batch: 1800  Loss: 0.00019072621944360435\n",
            "Epoch: 2  Batch: 2400  Loss: 0.0065691908821463585\n",
            "Epoch: 2  Batch: 3000  Loss: 0.2275204211473465\n",
            "Epoch: 2  Batch: 3600  Loss: 0.0007478914922103286\n",
            "Epoch: 2  Batch: 4200  Loss: 0.0019253992941230536\n",
            "Epoch: 2  Batch: 4800  Loss: 0.059512533247470856\n",
            "Epoch: 2  Batch: 5400  Loss: 0.0543813519179821\n",
            "Epoch: 2  Batch: 6000  Loss: 0.01018504612147808\n",
            "Epoch: 3  Batch: 600  Loss: 0.005499332211911678\n",
            "Epoch: 3  Batch: 1200  Loss: 0.026672279462218285\n",
            "Epoch: 3  Batch: 1800  Loss: 0.008007621392607689\n",
            "Epoch: 3  Batch: 2400  Loss: 9.643662633607164e-05\n",
            "Epoch: 3  Batch: 3000  Loss: 0.003329239785671234\n",
            "Epoch: 3  Batch: 3600  Loss: 0.06218495965003967\n",
            "Epoch: 3  Batch: 4200  Loss: 0.0006333804340101779\n",
            "Epoch: 3  Batch: 4800  Loss: 0.004127614665776491\n",
            "Epoch: 3  Batch: 5400  Loss: 0.01387433148920536\n",
            "Epoch: 3  Batch: 6000  Loss: 0.002550262724980712\n",
            "Epoch: 4  Batch: 600  Loss: 0.0008760752389207482\n",
            "Epoch: 4  Batch: 1200  Loss: 0.002810646314173937\n",
            "Epoch: 4  Batch: 1800  Loss: 0.0028930034022778273\n",
            "Epoch: 4  Batch: 2400  Loss: 6.752349145244807e-05\n",
            "Epoch: 4  Batch: 3000  Loss: 0.0002992989611811936\n",
            "Epoch: 4  Batch: 3600  Loss: 0.08674381673336029\n",
            "Epoch: 4  Batch: 4200  Loss: 0.04283095896244049\n",
            "Epoch: 4  Batch: 4800  Loss: 0.00030196557054296136\n",
            "Epoch: 4  Batch: 5400  Loss: 0.0006021805456839502\n",
            "Epoch: 4  Batch: 6000  Loss: 0.0017742315540090203\n",
            "Training Took: 3.510445257027944 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Z2w8DC3okw",
        "outputId": "14525f0b-0097-4b0a-ebf1-3d72e32fd6ef"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mu-az88/hand-digit-classification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76VZM1NW3pSl",
        "outputId": "5631ff91-3e05-49c3-ede6-b8ee4dbc30d6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hand-digit-classification'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    }
  ]
}